{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fourier transform is a way of expressing imformation in the **frequency domain** instead of the time domain. You can go back and forth from one to the other.\n",
    "\n",
    "It would be easiest to examine how the Fourier transform behaves in 1D before moving to 2D images. The expression for the 1D Fourier transform is:\n",
    "\n",
    "$$ F(u) = \\int_{\\infty}^{\\infty}{f(x)e^{-j2\\pi u x}dx} $$\n",
    "\n",
    "And the inverse transform (going back into the spatial domain):\n",
    "\n",
    "$$f(x) = \\int_{\\infty}^{\\infty}{F(u)e^{j2 \\pi u x}dx} $$\n",
    "\n",
    "But since we will be dealing with discrete-valued functions (images) we need to have a discrete form of the Fourier transform. This can be expressed as:\n",
    "\n",
    "$$F(u) = \\frac{1}{M} \\sum_{x=0}^{M-1}{f(x) e^{-j2 \\pi ux/M}} $$\n",
    "\n",
    "This is easiest to make sense of when you see a few example to get the idea of how the transform behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, figsize=(15,17))\n",
    "\n",
    "taxes = [0]*4\n",
    "for i, ax in enumerate(axes):\n",
    "    taxes[i] = ax.twinx()\n",
    "    ax.set_ylim([-1.2, 1.2])\n",
    "    taxes[i].set_ylim([-60, 280])\n",
    "\n",
    "axes[0].plot(x, y, c='k')\n",
    "taxes[0].bar(x, yf, width=0.03)\n",
    "\n",
    "axes[1].plot(x, y1, c='k')\n",
    "taxes[1].bar(x, y1f, width=0.03)\n",
    "\n",
    "axes[2].plot(x, y2, c='k')\n",
    "taxes[2].bar(x, y2f, width=0.03)\n",
    "\n",
    "axes[3].plot(x, y3, c='k')\n",
    "taxes[3].bar(x, y3f, width=0.03)\n",
    "#ax.bar(x, yf, width=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D version of the discrete Fourier transform has a similar expression:\n",
    "\n",
    "$$F(u,v) = \\frac{1}{MN}\\sum_{x=0}^{M-1}{\\sum_{y=0}^{N-1}{f(x,y) e^{-j2 \\pi (ux/M + vy/N)}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about an actual picture now? Let's try our trusty camera-man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is standard to center the spectrum. We will also perform a log adjustment to enhance the contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of trivial cases, it is usually impossible to make direct associations between specific components of an image and its transform. There are some general statements that we can make though:\n",
    "\n",
    "Since frequency is directly related to the rate of change, we can intuit that frequencies in the Fourier space correspond to patterns in the spatial domain. As we move away from the center, the low frequencies correspond to the slowly varying components of an image. Higher frequencies farther out from the center correspond to faster and faster gray level changes in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering in the frequency domain\n",
    "\n",
    "Filtering in the frequency domain consists of the following steps:\n",
    "\n",
    "1. Compute F(u,v) the DFT of the image.\n",
    "2. Center transform\n",
    "3. Multiply F(u,v) by a filter function H(u,v)\n",
    "4. Un-center the transform\n",
    "5. Computer the inverse\n",
    "6. Obtain the real part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It just so happens that F(0,0) = the average intensity of the original image. So, if we set this single value to zero, the average intensity of the image will be 0. This is known as a **notch filter**. That doesn't matter if we're scaling everything between 0 and 1, so we won't bother.\n",
    "\n",
    "Low frequencies are responsible for the general gray-level appearance of an image over smooth areas, while high frequencies are responsible for detail, such as edges and noise. A filter that attenuates high frequencies while \"passing\" low frequencies is called a **lowpass filter**. A filter that has the opposite effect is called a **highpass filter**. A low-pass filtered image would have less sharp detail, because high frequencies have been attenuated. A high-pass filtered image would have less gray-level variations in smooth areas and emphasized transitional (edge) gray-level details (e.g. a sharper image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should look a little familiar: didn't we get similar results from using convolutions in the spatial domain? Actually yes. We are just doing the same thing two different ways. A convolution in the spatial domain is the same as multiplication in the Fourier domain:\n",
    "\n",
    "$$f(x,y) * h(x,y) \\leftrightarrow F(u,v)H(u,v) $$\n",
    "\n",
    "Analogously:\n",
    "\n",
    "$$f(x,y)h(x,y) \\leftrightarrow F(u,v) * H(u,v) $$\n",
    "\n",
    "Why is this important? In general, if the filters are the same size, it is computationally more efficient to work in the frequency domain. But we often use smaller filters in the spatial domain-- in that case, it is more efficient to work in the spatial domain. You can also derive smaller spatial domain filters if you know the filter in the frequency domain. What is typically done in practice is to experiment in the frequency domain, obtain an H(u,v), then develop a smaller filter in the spatial domain based on H(u,v) that is used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try **ideal** filters, that are just binary filters, as opposed to gradually changing filters like the Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the odd ringing that occurs when using ideal filters. This is a characteristic of ideal filters. This can be explained if you look at the corresponding filter in the spatial domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, going to the center to construct a smaller filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centeral circle is responsible for the blurring in the processing image, while the concentric rings are responsible for the ringing behavior. Gaussian filters achieve blurring without ringing, because they have the central circle without the concentric rings.\n",
    "\n",
    "An intermediate filter is the **Butterworth filter**. It has the form:\n",
    "\n",
    "$$H(u,v) = \\frac{1}{1+[D(u,v)/D_0]^{2n}}$$\n",
    "\n",
    "where D is the distance from any point to the center:\n",
    "\n",
    "$$D(u,v) = [(u-M/2)^2+(v-N/2)^2]^{1/2} $$\n",
    "\n",
    "Where n is the order of the filter and $D_0$ is the cutoff frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Butterworth filter of order 1 has no ringing. Ringing is imperceptible with filters of order 2, but becomes more significant with higher order filters. It's an intermediate between ideal filters and Gaussian filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaPlacian in the filter domain\n",
    "\n",
    "\n",
    "Taking advantage of some properties of the Fourier transform:\n",
    "\n",
    "$$\\mathscr{F} \\bigg[ \\frac{\\partial^2 f(x,y)}{\\partial x^2} + \\frac{\\partial^2 f(x,y)}{\\partial y^2} \\bigg]  = (ju)^2F(u,v) + (jv)^2F(u,v) = -(u^2 + v^2)F(u,v)$$\n",
    "\n",
    "Thus, the LaPlacian filter:\n",
    "\n",
    "$$H(u,v) = -(u^2 + v^2) $$\n",
    "\n",
    "Correcting for centering:\n",
    "\n",
    "$$H(u,v) = -[(u-M/2)^2 + (v-N/2)^2] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
